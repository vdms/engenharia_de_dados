{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77f1aa51-3505-4d6c-85c5-5e380ccccce6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Client: Federal Government of Brazil / Central Bank of Brazil  \n",
    "Topic: PIX user behavior  \n",
    "Analyzed period: 2023 and 2024  \n",
    "Platform: Databricks Free Edition  \n",
    "Storage: Unity Catalog + Volumes\n",
    "---\n",
    "# Project Context\n",
    "\n",
    "This work is part of the MVP for the Data Engineering module and aims to build a cloud-based data pipeline, from data collection to analysis, using real and public data.\n",
    "\n",
    "The project was developed in a governmental context, considering the Central Bank as the main stakeholder. The focus is on analyzing the behavior of users of the PIX instant payment system, seeking to understand usage patterns over time, differences across user profiles, and regional variations.\n",
    "\n",
    "Although the project applies Data Engineering concepts and tools, it prioritizes clarity, organization, and end-to-end process understanding, focusing on building a functional and well-documented pipeline rather than overly complex solutions.\n",
    "\n",
    "---\n",
    "# Dataset Used\n",
    "\n",
    "The dataset used in this MVP comes from the Central Bank of Brazil through the PIX – Open Data initiative, made available via a public API.\n",
    "\n",
    "The data represents aggregated monthly statistics of PIX transactions, including information on transaction volume, total value, and general characteristics of the users involved, such as age group, region, transaction nature, and purpose.\n",
    "\n",
    "For this work, data from the years 2023 and 2024 was used, stored in two separate CSV files:\n",
    "\n",
    "* pix_2023.csv  \n",
    "* pix_2024.csv  \n",
    "\n",
    "The files were downloaded locally from the official API and later uploaded to the Databricks environment, where they became part of the raw data layer of the pipeline.\n",
    "\n",
    "Main columns used in the analysis:\n",
    "\n",
    "* AnoMes: transaction period (year and month)  \n",
    "* PAG_IDADE: payer age group  \n",
    "* REC_IDADE: receiver age group  \n",
    "* PAG_REGIAO: payer region  \n",
    "* REC_REGIAO: receiver region  \n",
    "* NATUREZA: transaction nature  \n",
    "* FINALIDADE: transaction purpose  \n",
    "* QUANTIDADE: number of transactions  \n",
    "* VALOR: total transacted value  \n",
    "\n",
    "In addition, some extra columns were kept in the raw data only for documentation and contextual purposes, but were not directly used in the final analyses.\n",
    "\n",
    "---\n",
    "# Data Pipeline Architecture\n",
    "\n",
    "To organize the pipeline, a layered architecture was adopted, widely used in data projects for facilitating separation of responsibilities and transformation traceability.\n",
    "\n",
    "## Bronze Layer (raw data)\n",
    "\n",
    "The Bronze layer contains the data exactly as obtained, without any transformation or analytical treatment.\n",
    "\n",
    "In this layer:\n",
    "\n",
    "* the original CSV files are stored in Databricks;  \n",
    "* the goal is to preserve the original data source;  \n",
    "* potential issues or inconsistencies are not yet addressed.\n",
    "\n",
    "This layer serves as a reliable reference point for auditing and reprocessing, if needed.\n",
    "\n",
    "## Silver Layer (processed data)\n",
    "\n",
    "The Silver layer contains cleaned and standardized data, ready for analytical modeling.\n",
    "\n",
    "At this stage:\n",
    "\n",
    "* data from 2023 and 2024 is unified;  \n",
    "* data types are adjusted (e.g., numeric values and dates);  \n",
    "* relevant columns are organized and standardized;  \n",
    "* the data gains a consistent structure.\n",
    "\n",
    "The goal of the Silver layer is to prepare the data for analysis without yet applying specific business rules.\n",
    "\n",
    "## Gold Layer (analytical model)\n",
    "\n",
    "The Gold layer represents the final analytical view of the data, structured to facilitate queries and analysis.\n",
    "\n",
    "In this layer:\n",
    "\n",
    "* data is organized into a star schema;  \n",
    "* dimension tables are created (time, user, region, nature, purpose);  \n",
    "* a fact table is created to concentrate the main transaction and value metrics.\n",
    "\n",
    "This structure enables clear and efficient answers to the business questions defined at the beginning of the project.\n",
    "\n",
    "---\n",
    "# Databricks Organization\n",
    "\n",
    "The project uses Unity Catalog for data organization, with the following structure:\n",
    "\n",
    "* Catalog: mvp_pix  \n",
    "* Schema: dados  \n",
    "* Volume (Bronze): /Volumes/mvp_pix/dados/bronze/\n",
    "\n",
    "This organization facilitates pipeline visualization, project documentation, and the generation of evidence for evaluation.\n",
    "\n",
    "---\n",
    "# Final Note\n",
    "\n",
    "This MVP does not aim to exhaust all analytical possibilities of the dataset, but rather to demonstrate, in a structured and functional way, the construction of a complete data pipeline—from data collection to analysis—with justified technical decisions and clear documentation."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00_context_and_setup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}